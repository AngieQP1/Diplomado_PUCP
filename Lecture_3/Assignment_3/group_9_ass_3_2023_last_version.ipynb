{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e752e246",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a1c69",
   "metadata": {},
   "source": [
    "## 1. Install and import libraries\n",
    "Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6903967",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "#### Importation of libraries\n",
    "First, we imported the libraries that would be needed for the completition of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e797bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For those with compatibility issues (python 3.10 and above):\n",
    "from collections import abc,  Counter, defaultdict, namedtuple, OrderedDict\n",
    "from collections.abc import Iterable\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pyreadstat as ps\n",
    "import savReaderWriter as sav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f586c",
   "metadata": {},
   "source": [
    "#### Import databases and creation of dictionnaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_1, metadata = ps.read_sav(\"../../_data/endes/2019/REC0111.sav\") #The function ps.read_sav was applied and saved as an object with the name of rec1\n",
    "rec_2, metadata = ps.read_sav(\"../../_data/endes/2019/RE223132.sav\")#The function ps.read_sav was applied and saved as an object with the name of rec2\n",
    "rec_3, metadata = ps.read_sav(\"../../_data/endes/2019/RE516171.sav\") #The function ps.read_sav was applied and saved as an object with the name of rec3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c758992",
   "metadata": {},
   "source": [
    "#### Creation of dictionnaries based on the headers of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62604c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sav.SavHeaderReader(\"../../_data/endes/2019/REC0111.sav\", #The function was called to act on the object REC011.sav. The with statement opens the file and then closes it when we're done\n",
    "                         ioUtf8=True) as header: #as header provides us with data from the SPSS file\n",
    "    metadata = header.all() #Retrieves all the metadata from the SPSS file and saves it in an object\n",
    "    value_labels1 = metadata.valueLabels #Stores just the metadata from the values in a new object\n",
    "    var_labels1 = metadata.varLabels    #Stores just the metadata from the variable labels in a new object\n",
    "    \n",
    "#The same is done with the other 2 files:\n",
    "  \n",
    "with sav.SavHeaderReader(\"../../_data/endes/2019/RE223132.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    value_labels2 = metadata.valueLabels\n",
    "    var_labels2 = metadata.varLabels    \n",
    "\n",
    "with sav.SavHeaderReader(\"../../_data/endes/2019/RE516171.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    value_labels3 = metadata.valueLabels\n",
    "    var_labels3 = metadata.varLabels  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e335e6",
   "metadata": {},
   "source": [
    "## 2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter. Update the dictionary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71303989",
   "metadata": {},
   "source": [
    "### _Solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d75a7",
   "metadata": {},
   "source": [
    "#### Selection of columns\n",
    "First, we create lists that contain the names of the variables to be used for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_rec_1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "columns_rec_2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "columns_rec_3 =['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b78f84",
   "metadata": {},
   "source": [
    "#### Creation of a new dataset\n",
    "The loc function was applied to the original dataset. The lists previously created were used as an argument of the function, instead of re-specifiyng them. The results were saved to a new dataset. This process was done for all 3 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6be442",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1_1 = rec_1.loc[:,columns_rec_1] \n",
    "rec2_1 = rec_2.loc[:,columns_rec_2]\n",
    "rec3_1 = rec_3.loc[:,columns_rec_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54c6dd",
   "metadata": {},
   "source": [
    "#### Update dictionnaries\n",
    "\n",
    "This code iterates through each pair of values and keys in the previously created object from section _1. Creation of dictionnaries based on the headers of the dataset_. It will only add the pairs to the dictionnary if the key is found on the columns of the rec1, rec2, and rec3 databases. The result is saved on new objects, such as `new_var_labels1`. \n",
    "\n",
    "This is the code for the variable labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var_labels1 = {key: value for key, value in var_labels1.items() if key in columns_rec_1}\n",
    "new_var_labels2 = {key: value for key, value in var_labels2.items() if key in columns_rec_2}\n",
    "new_var_labels3 = {key: value for key, value in var_labels3.items() if key in columns_rec_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca5389",
   "metadata": {},
   "source": [
    "The same is done for the value labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff97281",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_value_labels1 = {key: value for key, value in value_labels1.items() if key in columns_rec_1}\n",
    "new_value_labels2 = {key: value for key, value in value_labels2.items() if key in columns_rec_2}\n",
    "new_value_labels3 = {key: value for key, value in value_labels3.items() if key in columns_rec_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d7f28",
   "metadata": {},
   "source": [
    "## 3. Generate new columns\n",
    "Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed68f0",
   "metadata": {},
   "source": [
    "### _Solution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1708ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1_1.loc[:,'year']=2019 #Selection of all rows of the dataset if the value in the columns year is 2019\n",
    "var_labels1.update({'year': \"Year of the survey\"}) #Adds a new pair of variable and label to the dictionnary var_labels1\n",
    "new_var_labels1.update({'year': \"Year of the survey\"}) #Does the same for the dictionnary new_var_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5f9e32-e427-4214-849f-fea8e2144081",
   "metadata": {},
   "source": [
    "## 4. Merge\n",
    "Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf45644-291c-4530-9870-f0ac5d456be7",
   "metadata": {},
   "source": [
    "### Solution\n",
    "Using the pandas function merge, first rec1_1 and rec2_1 were merged based on the variable CASEID, using the method inner merge. This means that only the cases that appear on both files will be considered for merge. Then, that dataset was merged to rec3_1, using the same arguments and method. The result was saved to an object called `endes_2019`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10585dc-61e3-4536-84c7-08080ef642ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019 = pd.merge(pd.merge(rec1_1, rec2_1, on='CASEID', how='inner'), \n",
    "                      rec3_1, on='CASEID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1610851-b017-44f0-9610-093b14ed253e",
   "metadata": {},
   "source": [
    "## 5. Unification of variables\n",
    "Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c92b2-66ec-40ba-b0d8-360507ba94a9",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "All the labels are to be unified in one object, corresponding to both values and variables. First, it is done for the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0118d8a4-4638-4cd8-9c11-f9b7c34c7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_labels = {} #Creation of an empty dictionnary called var_labels\n",
    "var_labels.update(new_var_labels1) #var_labels dictionary is updated using the .update() method and new_var_labels1 is passed onto that\n",
    "var_labels.update(new_var_labels2) #var_labels dictionary is updated using the .update() method and new_var_labels2 is passed onto that\n",
    "var_labels.update(new_var_labels3) #var_labels dictionary is updated using the .update() method and new_var_labels3 is passed onto that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da43ff76-c6bf-4687-8b2e-32ce134c36be",
   "metadata": {},
   "source": [
    "Then, for the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8d2f9-4098-46b4-8e06-5553db875c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_labels = {} #Creation of an empty dictionnary called value_labels\n",
    "value_labels.update(new_value_labels1) #value_labels dictionary is updated using the .update() method and new_value_labels1 is passed onto that\n",
    "value_labels.update(new_value_labels2) #value_labels dictionary is updated using the .update() method and new_value_labels2 is passed onto that\n",
    "value_labels.update(new_value_labels3) #value_labels dictionary is updated using the .update() method and new_value_labels3 is passed onto that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa758a8-1fbd-4716-91e3-dc6a84b460ca",
   "metadata": {},
   "source": [
    "Afterwards, the results are saved to the file endes_2019 file using the function update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda48529-3a5d-4bca-b982-e9550d6637b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019.update({'var_labels': var_labels, 'value_labels': value_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29ca42-2825-4595-a192-d4bb25982cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019 #department (V024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730932d",
   "metadata": {},
   "source": [
    "## 6. Descriptive statistics\n",
    "Get the min, max, sd, n_obs, n_missing for the following columns **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)**. We want a dataframe with the following columns **Variables, Min, Max, Mean, N_obs, N_missing** and sort by the number of missing rows. **Hint: Use `describe` and `pivot` methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b5d424",
   "metadata": {},
   "source": [
    "### _Solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d2023",
   "metadata": {},
   "source": [
    "#### Step 1: Selection of columns and conversion to numeric\n",
    "The columns of interest ('V201', 'V613', 'V715', 'V511') are selected from 'endes_2019' data, and converted to numeric values using 'pd.to_numeric'. Non-numeric values are replaced with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb14ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['V201', 'V613', 'V715', 'V511']\n",
    "endes_2019_num = endes_2019[columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15991e",
   "metadata": {},
   "source": [
    "#### Step 2: Calculation of descriptive statistics and transposition\n",
    "Descriptive statistics are calculated for the numeric columns using the describe() method. \n",
    "The result is transposed so that statistics are in rows and variables in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447036c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_describe = endes_2019_num.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a0f4a6",
   "metadata": {},
   "source": [
    "#### Step 3: Addition of columns\n",
    "Two additional columns 'Missing' and 'N' are added to the 'stats_describe' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17910a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_describe['Missing'] = endes_2019_num.isnull().sum()\n",
    "stats_describe['N_obs'] = endes_2019_num.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db3a6a",
   "metadata": {},
   "source": [
    "#### Step 4: Rename columns\n",
    "Columns of descriptive statistics are renamed for better clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_describe = stats_describe.rename(columns={\n",
    "    'min': 'Min',\n",
    "    '25%': '25th Percentile',\n",
    "    '50%': 'Median',\n",
    "    '75%': '75th Percentile',\n",
    "    'max': 'Max',\n",
    "    'std': 'SD',\n",
    "    'mean': 'Mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c3f8f",
   "metadata": {},
   "source": [
    "#### Step 5: Reorganization of columns\n",
    "Columns are rearranged in the desired order for the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_describe = stats_describe[['Min', '25th Percentile', 'Median', '75th Percentile', 'Max', 'SD', 'Mean', 'N_obs', 'Missing']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f387e65",
   "metadata": {},
   "source": [
    "#### Step 6: Sort by 'Missing' in descending order\n",
    "The resulting dataframe is sorted based on the 'Missing' column in descending order. This places variables with more missing values at the top of the resulting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_describe = stats_describe.sort_values(by='Missing', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_describe #show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676f785",
   "metadata": {},
   "source": [
    "## 7. Grouping and Calculating Means\n",
    "Use `endes_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320e6fa",
   "metadata": {},
   "source": [
    "### _Solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f516b2a",
   "metadata": {},
   "source": [
    "#### Step 1: Column Names\n",
    "A list called 'name_colums' is defined with the names that each column will have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_columns = ['mean_total_children','mean_ideal_children', 'mean_hb_yr_educ', 'mean_first_marriage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c169417",
   "metadata": {},
   "source": [
    "#### Step 2: Conversion to Numeric\n",
    "In this code, the 'pd.to_numeric' function is used to convert the columns 'V201', 'V613', 'V715', 'V511' of the'endes_2019' data to numerical values. Additionally, the errors='coerce' parameter is used to replace any value that can't be converted to numeric with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019[columns] = endes_2019[columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f4e9c",
   "metadata": {},
   "source": [
    "#### Step 3: Grouping and Calculating Means\n",
    "This code group 'endes_2019' data by the columns 'V024' and 'year' and then calculates the average for each group on the columns specified in 'columns' variable (Step 2). \n",
    "The result is stored in a new object named 'mean_key_vars'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_key_vars = endes_2019.groupby(['V024', 'year'])[columns].mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd027309",
   "metadata": {},
   "source": [
    "#### Step 4: Column name change\n",
    "Finally, the columns of the 'mean_key_vars' are changed with the names specified in the names_colums list (Step 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccce6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_key_vars.columns=names_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef07be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_key_vars #show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f433d8",
   "metadata": {},
   "source": [
    "## 8. Resetting index, melting and rename columns\n",
    "Reshape `mean_key_vars` from wide to long. We want a dataframe with three columns **dpto, variables, values**. Name this object as `reshape_mean_key_vars`. **Hint: Use melt method**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e3c4f",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "With melt() method the 'mean_key_vars' data is reshaped from a wide format to a long format. This code takes the clustered 'mean_key_vars', resets its index, merges it to reshape it into a long format, and then renames the columns, specifically renaming 'V024' to 'dept'. This makes it easier to work with the data in a format that may be more suitable for certain analytical and visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_mean_key_vars = mean_key_vars.reset_index().melt(  #resetting index and melting\n",
    "    id_vars=['V024', 'year'],\n",
    "    var_name='variables',\n",
    "    value_name='values'\n",
    ").rename(columns={'V024': 'dpto'})  #renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "The result in a new object named 'reshape_mean_key_vars' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c69579",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_mean_key_vars  #show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e35a7",
   "metadata": {},
   "source": [
    "## 9. Replicate your answers for questions 7 and 8, but in one line of code\n",
    "Make it the most simple as possible. **NO HINT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b52b02",
   "metadata": {},
   "source": [
    "### _Solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1faa4c0",
   "metadata": {},
   "source": [
    "####  Replicate question 7\n",
    "This code groups the data by the 'V024' and 'year' columns, calculates the means of the specified columns, and renames the resulting columns with specific names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d4fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_key_vars_rep = endes_2019.groupby(['V024', 'year'])[columns].mean().rename(columns=dict(zip(columns, names_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb12f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_key_vars_rep  #show the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e47138",
   "metadata": {},
   "source": [
    "#### Replicate question 8\n",
    "This code reshape the 'mean_key_vars_rep' data from a wide format to a long format, keeping the columns 'V024' and 'year' as identifiers and renaming 'V024' to 'department'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90652118",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_mean_key_vars_rep = mean_key_vars.reset_index().melt(id_vars=['V024', 'year'], var_name='variables', value_name='values').rename(columns={'V024': 'dpto'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d512e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_mean_key_vars_rep  #show the result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
