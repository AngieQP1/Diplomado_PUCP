{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57607e9f",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8592720",
   "metadata": {},
   "source": [
    "## 1. Install and import libraries\n",
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41939807",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "#### Importation of libraries\n",
    "First, we imported the libraries that would be needed for the completition of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7246e3ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Iterable' from 'collections' (C:\\Users\\osman\\anaconda3\\Lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyreadstat\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msavReaderWriter\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msav\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\savReaderWriter\\__init__.py:138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mheader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msavReader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msavWriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msavHeaderReader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msavReaderNp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\savReaderWriter\\savWriter.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlocale\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     pandasOK \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Iterable' from 'collections' (C:\\Users\\osman\\anaconda3\\Lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pyreadstat\n",
    "import savReaderWriter as sav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d0fb34",
   "metadata": {},
   "source": [
    "#### Set up of the directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d2b943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Assignment_3.ipynb',\n",
       " 'Assignment_3_intento2.ipynb',\n",
       " 'Assignment_3_Yanell.ipynb',\n",
       " 'ass_3.py',\n",
       " 'ass_3_.py',\n",
       " 'FINAL.ipynb',\n",
       " 'intento 3.ipynb',\n",
       " 'Nueva carpeta',\n",
       " 'RE223132.sav',\n",
       " 'RE516171.sav',\n",
       " 'REC0111.csv',\n",
       " 'REC0111.sav']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% project working directory\n",
    "ruta_sdi = \"D:/Educaci√≥n y cosas importantes personal y profesionalmente/Universidad/Diplomado QLAB/2. Python/tarea 3\" #Defining a directory\n",
    "os.chdir(ruta_sdi) #Applying the function on the directory saved\n",
    "os.listdir(ruta_sdi) #Calling all the objects in the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece62321",
   "metadata": {},
   "source": [
    "#### Import databases and creation of dictionnaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65271cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = pd.read_spss(\"./REC0111.sav\") #The function pd.read_spss was applied and saved as an object with the name of rec1\n",
    "rec2 = pd.read_spss(\"./RE223132.sav\") #The function pd.read_spss was applied and saved as an object with the name of rec2\n",
    "rec3 = pd.read_spss(\"./RE516171.sav\") #The function pd.read_spss was applied and saved as an object with the name of rec3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b2031c",
   "metadata": {},
   "source": [
    "#### Creation of dictionnaries based on the headers of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814fadd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 10: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-37bab15dc2c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m with sav.SavHeaderReader(r\".\\REC0111.sav\", #The function was called to act on the object REC011.sav. The with statement opens the file and then closes it when we're done\n\u001b[0m\u001b[0;32m      2\u001b[0m                          ioUtf8=True) as header: #as header provides us with data from the SPSS file\n\u001b[0;32m      3\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Retrieves all the metadata from the SPSS file and saves it in an object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalue_labels1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalueLabels\u001b[0m \u001b[1;31m#Stores just the metadata from the values in a new object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvar_labels1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvarLabels\u001b[0m    \u001b[1;31m#Stores just the metadata from the variable labels in a new object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\savReaderWriter\\savHeaderReader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, savFileName, ioUtf8, ioLocale)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavFileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioUtf8\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioLocale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;34m\"\"\" Constructor. Initializes all vars that can be recycled \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         super(SavHeaderReader, self).__init__(savFileName, b\"rb\", None,\n\u001b[0m\u001b[0;32m     51\u001b[0m                                               ioUtf8, ioLocale)\n\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenSavFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\savReaderWriter\\header.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, savFileName, mode, refSavFileName, ioUtf8, ioLocale)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;34m\"\"\"Constructor\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHeader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavFileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioUtf8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioLocale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         self.fh = super(Header, self).openSavFile(savFileName, mode,\n\u001b[0m\u001b[0;32m     33\u001b[0m                                                   refSavFileName)\n\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvarNames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvarTypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvarNamesTypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\savReaderWriter\\generic.py\u001b[0m in \u001b[0;36mopenSavFile\u001b[1;34m(self, savFileName, mode, refSavFileName)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mexpandfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encodeFileName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0msavFileName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpandfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavFileName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavFileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf3 in position 10: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "with sav.SavHeaderReader(r\".\\REC0111.sav\", #The function was called to act on the object REC011.sav. The with statement opens the file and then closes it when we're done\n",
    "                         ioUtf8=True) as header: #as header provides us with data from the SPSS file\n",
    "    metadata = header.all() #Retrieves all the metadata from the SPSS file and saves it in an object\n",
    "    value_labels1 = metadata.valueLabels #Stores just the metadata from the values in a new object\n",
    "    var_labels1 = metadata.varLabels    #Stores just the metadata from the variable labels in a new object\n",
    "    \n",
    "#The same is done with the other 2 files:\n",
    "  \n",
    "with sav.SavHeaderReader(r\".\\RE223132.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    value_labels2 = metadata.valueLabels\n",
    "    var_labels2 = metadata.varLabels    \n",
    "\n",
    "with sav.SavHeaderReader( \".\\RE516171.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    value_labels3 = metadata.valueLabels\n",
    "    var_labels3 = metadata.varLabels  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cef74a7",
   "metadata": {},
   "source": [
    "## 2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter. Update the dictionary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c80ed",
   "metadata": {},
   "source": [
    "### _Solution_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c3589",
   "metadata": {},
   "source": [
    "#### Selection of columns\n",
    "First, we create lists that contain the names of the variables to be used for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73d53d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_rec1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "columns_rec2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "columns_rec3 =['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097cabe8",
   "metadata": {},
   "source": [
    "#### Creation of a new dataset\n",
    "The loc function was applied to the original dataset. The lists previously created were used as an argument of the function, instead of re-specifiyng them. The results were saved to a new dataset. This process was done for all 3 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb6d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1_1 = rec1.loc[:,columns_rec1] \n",
    "rec2_1 = rec2.loc[:,columns_rec2]\n",
    "rec3_1 = rec3.loc[:,columns_rec3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9771d0",
   "metadata": {},
   "source": [
    "#### Update dictionnaries\n",
    "\n",
    "This code iterates through each pair of values and keys in the previously created object from section _1. Creation of dictionnaries based on the headers of the dataset_. It will only add the pairs to the dictionnary if the key is found on the columns of the rec1, rec2, and rec3 databases. The result is saved on new objects, such as `new_var_labels1`. \n",
    "\n",
    "This is the code for the variable labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7eca2aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'var_labels1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a4a34b83ae03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_var_labels1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar_labels1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns_rec1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew_var_labels2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar_labels2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns_rec2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_var_labels3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar_labels3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns_rec3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'var_labels1' is not defined"
     ]
    }
   ],
   "source": [
    "new_var_labels1 = {key: value for key, value in var_labels1.items() if key in columns_rec1}\n",
    "new_var_labels2 = {key: value for key, value in var_labels2.items() if key in columns_rec2}\n",
    "new_var_labels3 = {key: value for key, value in var_labels3.items() if key in columns_rec3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2198fa",
   "metadata": {},
   "source": [
    "The same is done for the value labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "181a9116",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value_labels1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d9267aff1dea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_value_labels1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue_labels1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns_rec1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnew_value_labels2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue_labels2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns_rec2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnew_value_labels3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalue_labels3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns_rec3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'value_labels1' is not defined"
     ]
    }
   ],
   "source": [
    "new_value_labels1 = {key: value for key, value in value_labels1.items() if key in columns_rec1}\n",
    "new_value_labels2 = {key: value for key, value in value_labels2.items() if key in columns_rec2}\n",
    "new_value_labels3 = {key: value for key, value in value_labels3.items() if key in columns_rec3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261a326",
   "metadata": {},
   "source": [
    "## 3. Generate new columns\n",
    "Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d2bae",
   "metadata": {},
   "source": [
    "### _Solution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3164fda3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rec1_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rec1_1\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2019\u001b[39m \u001b[38;5;66;03m#Selection of all rows of the dataset if the value in the columns year is 2019\u001b[39;00m\n\u001b[0;32m      2\u001b[0m var_labels1\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear of the survey\u001b[39m\u001b[38;5;124m\"\u001b[39m}) \u001b[38;5;66;03m#Adds a new pair of variable and label to the dictionnary var_labels1\u001b[39;00m\n\u001b[0;32m      3\u001b[0m new_var_labels1\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear of the survey\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rec1_1' is not defined"
     ]
    }
   ],
   "source": [
    "rec1_1.loc[:,'year']=2019 #Selection of all rows of the dataset if the value in the columns year is 2019\n",
    "var_labels1.update({'year': \"Year of the survey\"}) #Adds a new pair of variable and label to the dictionnary var_labels1\n",
    "new_var_labels1.update({'year': \"Year of the survey\"}) #Does the same for the dictionnary new_var_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f09cf5",
   "metadata": {},
   "source": [
    "## 4. Merge\n",
    "Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17825cf",
   "metadata": {},
   "source": [
    "### Solution\n",
    "Using the pandas function merge, first rec1_1 and rec2_1 were merged based on the variable CASEID, using the method inner merge. This means that only the cases that appear on both files will be considered for merge. Then, that dataset was merged to rec3_1, using the same arguments and method. The result was saved to an object called `endes_2019`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019 = pd.merge(pd.merge(rec1_1, rec2_1, on='CASEID', how='inner'), \n",
    "                      rec3_1, on='CASEID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a846d7f",
   "metadata": {},
   "source": [
    "## 5. Unification of variables\n",
    "Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086bebb",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "All the labels are to be unified in one object, corresponding to both values and variables. First, it is done for the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7371de9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_var_labels1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m var_labels \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;66;03m#Creation of an empty dictionnary called var_labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m var_labels\u001b[38;5;241m.\u001b[39mupdate(new_var_labels1) \u001b[38;5;66;03m#var_labels dictionary is updated using the .update() method and new_var_labels1 is passed onto that\u001b[39;00m\n\u001b[0;32m      3\u001b[0m var_labels\u001b[38;5;241m.\u001b[39mupdate(new_var_labels2) \u001b[38;5;66;03m#var_labels dictionary is updated using the .update() method and new_var_labels2 is passed onto that\u001b[39;00m\n\u001b[0;32m      4\u001b[0m var_labels\u001b[38;5;241m.\u001b[39mupdate(new_var_labels3)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_var_labels1' is not defined"
     ]
    }
   ],
   "source": [
    "var_labels = {} #Creation of an empty dictionnary called var_labels\n",
    "var_labels.update(new_var_labels1) #var_labels dictionary is updated using the .update() method and new_var_labels1 is passed onto that\n",
    "var_labels.update(new_var_labels2) #var_labels dictionary is updated using the .update() method and new_var_labels2 is passed onto that\n",
    "var_labels.update(new_var_labels3) #var_labels dictionary is updated using the .update() method and new_var_labels3 is passed onto that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49825e4",
   "metadata": {},
   "source": [
    "Then, for the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b04ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_labels = {} #Creation of an empty dictionnary called value_labels\n",
    "value_labels.update(new_value_labels1) #value_labels dictionary is updated using the .update() method and new_value_labels1 is passed onto that\n",
    "value_labels.update(new_value_labels2) #value_labels dictionary is updated using the .update() method and new_value_labels2 is passed onto that\n",
    "value_labels.update(new_value_labels3) #value_labels dictionary is updated using the .update() method and new_value_labels3 is passed onto that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74753fe7",
   "metadata": {},
   "source": [
    "Afterwards, the results are saved to the file endes_2019 file using the function update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5339dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019.update({'var_labels': var_labels, 'value_labels': value_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1237d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019 #department (V024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
