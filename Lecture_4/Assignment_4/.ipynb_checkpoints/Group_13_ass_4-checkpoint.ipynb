{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828e88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84254d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyreadstat in c:\\users\\daniel.montjoy\\appdata\\roaming\\python\\python311\\site-packages (1.2.5)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyreadstat) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7820624",
   "metadata": {},
   "source": [
    "1. Import the REC0111.sav, RE223132.sav and RE516171.sav files and their variables and values labels from this path \"../../_data/endes/2019\". The name of imported files should be named as rec_1, rec_2 and rec_3 for files REC0111.sav, RE223132.sav and RE516171.sav respectively. The name of the variable and value labels should be var_labels1 and value_labels1 for rec1, var_labels2 and value_labels2 for rec2, and var_labels3 and value_labels3 for rec3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea999a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define the route where the files are located\n",
    "p = '''../../_data/endes/2019'''\n",
    "# we save the route of the three files\n",
    "\n",
    "d1 = p+'''/REC0111.sav'''\n",
    "d2 = p+'''/RE223132.sav'''\n",
    "d3 = p+'''/RE516171.sav'''\n",
    "#we import the sav files as pandas data frames (rec_x) and as an objetct with the metadata from the file (meta_x)\\n\"\n",
    "rec_1,meta_1 = pyreadstat.read_sav(d1)\n",
    "rec_2,meta_2 = pyreadstat.read_sav(d2)\n",
    "rec_3,meta_3 = pyreadstat.read_sav(d3)\n",
    "\n",
    "#we create dictionaries with the labels of variables and values of variables\n",
    "\n",
    "var_labels1 = meta_1.column_names_to_labels\n",
    "value_labels1 = meta_1.variable_value_labels\n",
    "\n",
    "var_labels2 = meta_2.column_names_to_labels\n",
    "value_labels2 = meta_2.variable_value_labels\n",
    "\n",
    "var_labels3 = meta_3.column_names_to_labels\n",
    "value_labels3 = meta_3.variable_value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe119325",
   "metadata": {},
   "source": [
    "2. Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as rec1_1, rec2_1, and rec3_1. The new varible labels objects should be named as new_var_labels1, new_var_labels2, and new_var_labels3. The new value labels objects should be named as new_value_labels1, new_value_labels2, and new_value_labels3 Hint: Use the loc and column names to filter, for loop, and this link to update the var and value dictionary.\n",
    "\n",
    "rec1\tCASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133\n",
    "rec2\tCASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380\n",
    "rec3\tCASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10faabe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a new data keeping all the cases for the indicated variables\n",
    "r1 = ['CASEID', 'V000', 'V001', 'V002','V003' , 'V004','V007','V008' ,'V009' ,'V010' , 'V011', 'V012', 'V024', 'V102','V120' , 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "\n",
    "r2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "\n",
    "r3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "\n",
    "rec1_1=rec_1.loc[:,r1]\n",
    "\n",
    "rec2_1=rec_2.loc[:,r2]\n",
    "\n",
    "rec3_1=rec_3.loc[:,r3]\n",
    "#We create a list with the names of the variables we are selecting to keep \n",
    "\n",
    "new_var_labels1 = {}\n",
    "new_value_labels1 = {}\n",
    "\n",
    "new_var_labels2 = {}\n",
    "new_value_labels2 = {}\n",
    "\n",
    "new_var_labels3 = {}\n",
    "new_value_labels3 = {}\n",
    "\n",
    "#We create the new labels dictionaries keeping only the keys that are in the clave_selection lists\n",
    "for clave in var_labels1.keys():\n",
    "    if clave in r1:\n",
    "        new_var_labels1[clave] = var_labels1[clave]\n",
    "\n",
    "for clave in value_labels1.keys():\n",
    "    if clave in r1:\n",
    "        new_value_labels1[clave] = value_labels1[clave]\n",
    "        \n",
    "\n",
    "for clave in var_labels2.keys():\n",
    "    if clave in r2:\n",
    "        new_var_labels2[clave] = var_labels2[clave]\n",
    "\n",
    "for clave in value_labels2.keys():\n",
    "    if clave in r2:\n",
    "        new_value_labels2[clave] = value_labels2[clave]\n",
    "        \n",
    "\n",
    "for clave in var_labels3.keys():\n",
    "    if clave in r3:\n",
    "        new_var_labels3[clave] = var_labels3[clave]\n",
    "\n",
    "for clave in value_labels3.keys():\n",
    "    if clave in r3:\n",
    "        new_value_labels3[clave] = value_labels3[clave]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db3899",
   "metadata": {},
   "source": [
    "3. Generate a new column for rec1_1 named as year. It should be equal to 2019. Also, you must update this new variable for the var_labels dictionary. Generate a new key for new_var_labels1 and the value for this key should be \"Year of the survey\" Hint: Use loc and update method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8b25282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a new column named 'year' in rec1_1 and update var_labels dictionary\n",
    "rec1_1['year'] = 2019\n",
    "\n",
    "# Update new_var_labels1 dictionary with the new variable 'year'\n",
    "new_var_labels1['year'] = \"Year of the survey\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a64c0a",
   "metadata": {},
   "source": [
    "rec1_1['year'] = 2019: This line adds a new column named 'year' to the DataFrame rec1_1 and assigns the value 2019 to all rows in that column.\n",
    "\n",
    "new_var_labels1['year'] = \"Year of the survey\": This line adds a new key-value pair to the new_var_labels1 dictionary. The key is 'year', which is the name of the new variable, and the value is \"Year of the survey,\" which represents the label for the new variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41dbd32",
   "metadata": {},
   "source": [
    "4. Merge rec1_1, rec2_1, and rec3_1 using CASEID. Name this new object as endes_2019. Hint: Use this link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0422dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Merge rec1_1, rec2_1, and rec3_1 using CASEID\n",
    "endes_2019 = pd.merge(rec1_1, rec2_1, on='CASEID', how='inner')\n",
    "endes_2019 = pd.merge(endes_2019, rec3_1, on='CASEID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ca34c",
   "metadata": {},
   "source": [
    "pd.merge(rec1_1, rec2_1, on='CASEID', how='inner'): This line performs an inner merge between rec1_1 and rec2_1 based on the 'CASEID' column. The result is stored in a temporary DataFrame.\n",
    "\n",
    "pd.merge(endes_2019, rec3_1, on='CASEID', how='inner'): This line performs another inner merge, this time between the temporary DataFrame from step 1 (endes_2019) and rec3_1 based on the 'CASEID' column. The final result is stored in the endes_2019 DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40969601",
   "metadata": {},
   "source": [
    "5. Unify all the new_var_labels in one object and new_value_labels in another one object. Name these two objects as var_labels and value_labels. Use them to generate new attributes for endes_2019. These attributes should be named as var_labels and value_labels. Hint: Use update method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify new_var_labels into var_labels\n",
    "var_labels = {}\n",
    "var_labels.update(new_var_labels1)\n",
    "var_labels.update(new_var_labels2)\n",
    "var_labels.update(new_var_labels3)\n",
    "\n",
    "# Unify new_value_labels into value_labels\n",
    "value_labels = {}\n",
    "value_labels.update(new_value_labels1)\n",
    "value_labels.update(new_value_labels2)\n",
    "value_labels.update(new_value_labels3)\n",
    "\n",
    "# Add new attributes var_labels and value_labels to endes_2019\n",
    "endes_2019.var_labels = var_labels\n",
    "endes_2019.value_labels = value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c398828",
   "metadata": {},
   "source": [
    "var_labels = {}: This line initializes an empty dictionary to store the unified variable labels.\n",
    "\n",
    "var_labels.update(new_var_labels1), var_labels.update(new_var_labels2), var_labels.update(new_var_labels3): These lines update the var_labels dictionary with the contents of each new_var_labels dictionary.\n",
    "\n",
    "value_labels = {}: This line initializes an empty dictionary to store the unified value labels.\n",
    "\n",
    "value_labels.update(new_value_labels1), value_labels.update(new_value_labels2), value_labels.update(new_value_labels3): These lines update the value_labels dictionary with the contents of each new_value_labels dictionary.\n",
    "\n",
    "endes_2019.var_labels = var_labels: This line adds a new attribute named var_labels to the endes_2019 DataFrame and assigns the var_labels dictionary to it.\n",
    "\n",
    "endes_2019.value_labels = value_labels: This line adds a new attribute named value_labels to the endes_2019 DataFrame and assigns the value_labels dictionary to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0916384",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years 2019, 2018, 2017, 2016, 2015. Import the REC0111.sav, RE223132.sav and RE516171.sav files and their variables and values labels from this path \"../../_data/endes/\". For this excersie you must use a for loop. This loop must iterate over 2019, 2018, 2017, 2016, 2015 folders and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as all_data. The keys of the dictionary should be named as year_2019, for example, and the keys of the nested dictionary should be data, var_labels, and value_labels. Hint: Use this link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b6a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
