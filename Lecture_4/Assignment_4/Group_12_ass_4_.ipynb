{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9bd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc59fac",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# File paths for the .sav files\n",
    "file_paths = {\n",
    "    \"REC0111.sav\": \"../../_data/endes/2019/REC0111.sav\",\n",
    "    \"RE223132.sav\": \"../../_data/endes/2019/RE223132.sav\",\n",
    "    \"RE516171.sav\": \"../../_data/endes/2019/RE516171.sav\"\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store dataframes, variable labels, and value labels\n",
    "dataframes = {}\n",
    "var_labels = {}\n",
    "value_labels = {}\n",
    "\n",
    "# Read each .sav file and store its contents and metadata\n",
    "for file_name, file_path in file_paths.items():\n",
    "    df, meta = pyreadstat.read_sav(file_path)\n",
    "    dataframes[file_name] = df\n",
    "    var_labels[file_name] = meta.column_labels  # Updated this line\n",
    "    value_labels[file_name] = meta.variable_value_labels\n",
    "\n",
    "# Assigning the dataframes and labels to the specified names\n",
    "rec_1, rec_2, rec_3 = [dataframes[file] for file in file_paths]\n",
    "var_labels1, var_labels2, var_labels3 = [var_labels[file] for file in file_paths]\n",
    "value_labels1, value_labels2, value_labels3 = [value_labels[file] for file in file_paths]\n",
    "\n",
    "# Displaying the first few rows of each dataframe as an example\n",
    "print(rec_1.head())\n",
    "print(rec_2.head())\n",
    "print(rec_3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64eeb3",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76da95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names to be selected for each dataframe\n",
    "columns_rec1 = [\"CASEID\", \"V000\", \"V001\", \"V002\", \"V003\", \"V004\", \"V007\", \"V008\", \"V009\", \"V010\", \"V011\", \"V012\", \"V024\", \"V102\", \"V120\", \"V121\", \"V122\", \"V123\", \"V124\", \"V125\", \"V127\", \"V133\"]\n",
    "columns_rec2 = [\"CASEID\", \"V201\", \"V218\", \"V301\", \"V302\", \"V323\", \"V323A\", \"V325A\", \"V326\", \"V327\", \"V337\", \"V359\", \"V360\", \"V361\", \"V362\", \"V363\", \"V364\", \"V367\", \"V372\", \"V372A\", \"V375A\", \"V376\", \"V376A\", \"V379\", \"V380\"]\n",
    "columns_rec3 = [\"CASEID\", \"V501\", \"V502\", \"V503\", \"V504\", \"V505\", \"V506\", \"V507\", \"V508\", \"V509\", \"V510\", \"V511\", \"V512\", \"V513\", \"V525\", \"V613\", \"V714\", \"V715\"]\n",
    "\n",
    "# Selecting columns\n",
    "rec1_1 = rec_1.loc[:, columns_rec1]\n",
    "rec2_1 = rec_2.loc[:, columns_rec2]\n",
    "rec3_1 = rec_3.loc[:, columns_rec3]\n",
    "\n",
    "# Funci√≥n para actualizar las etiquetas de valor\n",
    "def update_value_labels(original_value_labels, selected_columns):\n",
    "    return {key: value for key, value in original_value_labels.items() if key in selected_columns}\n",
    "\n",
    "# Actualizar solo las etiquetas de valor si son diccionarios\n",
    "new_value_labels1 = update_value_labels(value_labels1, columns_rec1)\n",
    "new_value_labels2 = update_value_labels(value_labels2, columns_rec2)\n",
    "new_value_labels3 = update_value_labels(value_labels3, columns_rec3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "367ee873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V000</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V007</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>V010</th>\n",
       "      <th>...</th>\n",
       "      <th>V024</th>\n",
       "      <th>V102</th>\n",
       "      <th>V120</th>\n",
       "      <th>V121</th>\n",
       "      <th>V122</th>\n",
       "      <th>V123</th>\n",
       "      <th>V124</th>\n",
       "      <th>V125</th>\n",
       "      <th>V127</th>\n",
       "      <th>V133</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000100201  3</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000102801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000102801  6</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000104801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38330</th>\n",
       "      <td>325406201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38331</th>\n",
       "      <td>325406301  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38332</th>\n",
       "      <td>325407001  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38333</th>\n",
       "      <td>325407201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38334</th>\n",
       "      <td>325407401  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38335 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CASEID V000    V001  V002  V003    V004    V007    V008  \\\n",
       "0            000100201  2  PE6     1.0   2.0   2.0     1.0  2019.0  1434.0   \n",
       "1            000100201  3  PE6     1.0   2.0   3.0     1.0  2019.0  1434.0   \n",
       "2            000102801  2  PE6     1.0  28.0   2.0     1.0  2019.0  1434.0   \n",
       "3            000102801  6  PE6     1.0  28.0   6.0     1.0  2019.0  1434.0   \n",
       "4            000104801  2  PE6     1.0  48.0   2.0     1.0  2019.0  1434.0   \n",
       "...                   ...  ...     ...   ...   ...     ...     ...     ...   \n",
       "38330        325406201  2  PE6  3254.0  62.0   2.0  3254.0  2019.0  1440.0   \n",
       "38331        325406301  2  PE6  3254.0  63.0   2.0  3254.0  2019.0  1440.0   \n",
       "38332        325407001  2  PE6  3254.0  70.0   2.0  3254.0  2019.0  1440.0   \n",
       "38333        325407201  2  PE6  3254.0  72.0   2.0  3254.0  2019.0  1440.0   \n",
       "38334        325407401  2  PE6  3254.0  74.0   2.0  3254.0  2019.0  1440.0   \n",
       "\n",
       "       V009    V010  ...  V024  V102  V120  V121  V122  V123  V124  V125  \\\n",
       "0       4.0  1986.0  ...   1.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0   \n",
       "1       1.0  2007.0  ...   1.0   1.0   1.0   1.0   1.0   0.0   0.0   0.0   \n",
       "2       6.0  1983.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   \n",
       "3       3.0  1970.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   \n",
       "4       5.0  1991.0  ...   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "...     ...     ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "38330  12.0  1971.0  ...  25.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "38331   6.0  1988.0  ...  25.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "38332   7.0  1973.0  ...  25.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "38333  12.0  1994.0  ...  25.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "38334  10.0  1996.0  ...  25.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "       V127  V133  \n",
       "0      33.0  16.0  \n",
       "1      33.0   6.0  \n",
       "2      33.0  16.0  \n",
       "3      33.0   4.0  \n",
       "4      34.0   1.0  \n",
       "...     ...   ...  \n",
       "38330  96.0   4.0  \n",
       "38331  96.0   6.0  \n",
       "38332  96.0   3.0  \n",
       "38333  96.0   9.0  \n",
       "38334  96.0   9.0  \n",
       "\n",
       "[38335 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ec49b",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9c141",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad9e4b",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2d6978",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b35f51",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03925b90",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0dec1",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33cbff",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
