{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1da47d7-0efe-4ba8-82a8-709ad6b161f8",
   "metadata": {},
   "source": [
    "# 1 Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e561c0f-a8e0-48e1-9a30-01fd1189bc04",
   "metadata": {},
   "source": [
    "## 1. Install and import libraries\n",
    " Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145cb2b4-55f5-4a8b-bd2f-9921e8c10402",
   "metadata": {},
   "source": [
    "### _Solution_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1769dc-901a-4bda-abbc-93dd752e5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For those with compatibility issues (python 3.10 and above):\n",
    "from collections import abc,  Counter, defaultdict, namedtuple, OrderedDict\n",
    "from collections.abc import Iterable\n",
    "import collections.abc\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff632f-61da-4b5b-a44c-a417693c2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "import urllib.request\n",
    "import savReaderWriter as sav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb375f8-073f-48cf-b5c6-54568f8e2391",
   "metadata": {},
   "source": [
    "#### 1.2 Loop-Based Processing of Multiple SPSS Data Files with Pandas and savReaderWriter\n",
    "In this code, a file path and a list of file names are specified. Subsequently, three empty lis(`recs`, `var_labels`, and `value_labels`),ls) are initialized to store data, variable labels, and value labels, respectively. The code then enters a loop where, for each file in the list, it constructs the full file path, assigns dynamic names to variables, and reads the data and metadata from an SPSS (.sav) file using the SavReader module. The obtained data, variable labels, and value labels are then stored in the respective lis\n",
    "\n",
    "Within the loop, the code reads the data from each .sav file and stores it in a Pandas DataFrame. The variable labels and value labels are also extracted from the file. The obtained data, variable labels, and value labels are then appended to their respective lists (`recs`, `var_labels`, and `value_labels`). Additionally, the code dynamically assigns variable names to the loaded data and labels using the locals() function, ensuring that the variables are easily accessible and identifiable.ts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e195d2ea-6355-4227-b01f-9e7daa872b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:\\\\tarea 3\\\\_data\\\\endes\\\\2019\"\n",
    "file_names = [\"REC0111.sav\", \"RE223132.sav\", \"RE516171.sav\"]\n",
    "\n",
    "recs = []\n",
    "var_labels = []\n",
    "value_labels = []\n",
    "\n",
    "for i, file_name in enumerate(file_names, start=1):\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    rec_name = f\"rec_{i}\"\n",
    "    var_labels_name = f\"var_labels{i}\"\n",
    "    value_labels_name = f\"value_labels{i}\"\n",
    "\n",
    "    # Read the .sav file\n",
    "    with sav.SavReader(file_path, ioUtf8=True) as reader:\n",
    "        # Obtener datos y metadatos\n",
    "        data = pd.DataFrame(reader.all(), columns=reader.header)\n",
    "        var_labels_data = reader.varLabels\n",
    "        value_labels_data = reader.valueLabels\n",
    "\n",
    "    # Store data and labels in lists.\n",
    "    recs.append(data)\n",
    "    var_labels.append(var_labels_data)\n",
    "    value_labels.append(value_labels_data)\n",
    "\n",
    "    # Assign variable names and labels.\n",
    "    locals()[rec_name] = data\n",
    "    locals()[var_labels_name] = var_labels_data\n",
    "    locals()[value_labels_name] = value_labels_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67069aa0-a527-4447-8021-b98853e701f7",
   "metadata": {},
   "source": [
    "Now, the data is stored in rec_1, rec_2, and rec_3, and the labels in var_labels1, var_labels2, var_labels3, value_labels1, value_labels2\n",
    ", value_labels3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef594fbf-cb76-4172-a3c9-9fae1bf30238",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938c2c5-7e07-4cc1-9839-87c9ac23c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40160f7e-6c42-4642-90f8-d84dfbc8f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465c6e8-89a0-439a-8cff-bfde966833b8",
   "metadata": {},
   "source": [
    "## 2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d80ed-145b-4de4-9a58-1aa238e38d00",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "#### 2.1. Selection of columns\n",
    "First, we create lists that contain the names of the variables to be used for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f1975-fbf8-43a1-8a4a-ed553f61a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_rec1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "columns_rec2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "columns_rec3 =['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf650f-1c29-4768-ba65-f4a87bd1e989",
   "metadata": {},
   "source": [
    "#### 2.2 Creation of a new dataset\n",
    "Now, the code dynamically creates new variables for each iteration of the loop, containing subsets of data, variable labels, and value labels based on the specified columns for each dataframe in the `rec` list.\n",
    "\n",
    "The code begins by defining a list of specific columns that will be used to extract data subsets from various DataFrames. It then employs a loop to iterate through each DataFrame in the recs list. During each iteration, dynamic variable names are generated to store the results of the subset, including a modified version of the original DataFrame, variable labels, and value labels. This dynamic approach allows for efficient and structured subset operations for each DataFrame.\n",
    "\n",
    "Within the loop, the code uses the loc function to select specific columns from the current DataFrame. These data subsets are stored in new variables with dynamic names, such as reci_1. Additionally, subsets of variable labels (new_var_labelsi) and value labels (new_value_labelsi) are generated. These subsets are created by filtering the original labels, retaining only those corresponding to the selected specific columns. This approach ensures that the new datasets and labels are tailored and contain only relevant information for the specified columns, facilitating subsequent analysis or data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f773402-cf86-49b5-bcf9-495f4f97af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_recs = [columns_rec1, columns_rec2, columns_rec3]\n",
    "for i in range(len(recs)):\n",
    "        reci_1 = f\"rec{i+1}_1\"\n",
    "        new_var_labelsi = f\"new_var_labels{i+1}\"\n",
    "        new_value_labelsi = f\"new_value_labels{i+1}\"\n",
    "    \n",
    "        locals()[reci_1] = recs[i].loc[:, columns_recs[i]]\n",
    "        locals()[new_var_labelsi] = {key : value for key, value in var_labels[i].items() if key in columns_recs[i]}\n",
    "        locals()[new_value_labelsi] = {key: value for key, value in value_labels[i].items() if key in columns_recs[i]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b60389-3007-40f3-b8d7-9333722e2af1",
   "metadata": {},
   "source": [
    "## 3. Generate new columns\n",
    "Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4e6e4-1a15-4d5a-8311-4ca005756f34",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "In this code, a specific action is performed on the DataFrame `rec1_1`. All rows of the dataset where the value in the 'year' column equals 2019 are selected using the expression `rec1_1.loc[:,'year']=2019`. Subsequently, the variable labels associated with the DataFrame are updated: a new variable-label pair is added, where the variable is 'year' and the label is \"Year of the survey,\" both in the original dictionary `var_labels1` and in a new dictionary named `new_var_labels1`. This process ensures that the labels associated with the 'year' variable are kept updated with information relevant to the survey year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac3e34-049d-4dff-9a53-37dc6613e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1_1.loc[:,'year']=2019 #Selection of all rows of the dataset if the value in the columns year is 2019\n",
    "var_labels1.update({'year': \"Year of the survey\"}) #Adds a new pair of variable and label to the dictionnary var_labels1\n",
    "new_var_labels1.update({'year': \"Year of the survey\"}) #Does the same for the dictionnary new_var_labels1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bebffa-f0b6-49e6-934f-43df826b88fb",
   "metadata": {},
   "source": [
    "## 4. Merge\n",
    "Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3b682-4327-4bdc-be3b-8f6bf7a23181",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "\n",
    "Using the pandas function merge, first `rec1_1` and `rec2_1` were merged based on the variable CASEID, using the method inner merge. This means that only the cases that appear on both files will be considered for merge. Then, that dataset was merged to `rec3_1`, using the same arguments and method. The result was saved to an object called `endes_2019`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533b366-d805-44a2-b874-fef543c9ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019 = pd.merge(pd.merge(rec1_1, rec2_1, on='CASEID', how='inner'), \n",
    "                      rec3_1, on='CASEID', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a467735-a086-4bea-9e23-44a0382c6c62",
   "metadata": {},
   "source": [
    "Then, we checked the overview of the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b4760-b60b-41d9-a2d9-5e8e49d22e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the structure of endes_2019\n",
    "endes_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a6b86-b358-4a10-a8e9-53a09919d821",
   "metadata": {},
   "source": [
    "## 5. Unification of variables\n",
    "Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2da45-0354-4b61-8a81-bc90cbcf1a93",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "All the labels are to be unified in one object, corresponding to both values and variables. First, it is done for the variables, then, for the values. For this purpose, what we did was, briefly, create empty dictionnaries that would contain the variables to be updated, then create lists and finally automatize the process with a `for loop`.\n",
    "\n",
    "#### Step 1: Creation and update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d241d-087a-4f51-a583-9824b40ac28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dictionnaries\n",
    "var_labels = {}\n",
    "value_labels = {}\n",
    "\n",
    "#Variable labels\n",
    "var_labels.update(new_var_labels1) #var_labels dictionary is updated using the .update() method. The update adds new_var_labels1\n",
    "var_labels.update(new_var_labels2) #var_labels dictionary is updated using the .update() method. The update adds_labels2\n",
    "var_labels.update(new_var_labels3) #var_labels dictionary is updated using the .update() method. The update adds var_labels3\n",
    "\n",
    "#Value labels\n",
    "value_labels.update(new_value_labels1) #value_labels dictionary is updated using the .update() method. The update adds new_value_labels1 \n",
    "value_labels.update(new_value_labels2) #value_labels dictionary is updated using the .update() method. The update adds new_value_labels2\n",
    "value_labels.update(new_value_labels3) #value_labels dictionary is updated using the .update() method. The update adds new_value_labels3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e61b21-a4f9-4200-93ee-a8249afb5d25",
   "metadata": {},
   "source": [
    "#### Step 2: Creation of lists and `for loop`\n",
    "Afterwards, as preparation to tasks to follow (6-10), we did the following:\n",
    "* Create 2 lists: one, composed of the variable labels and value labels objects\n",
    "* Create a `for loop` that automatically updates the dictionnaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51a2b5-6cc5-4015-9144-21f17d3974f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of lists \n",
    "new_var_labels_list = [new_var_labels1, new_var_labels2, new_var_labels3] #new object composed of the objects in between the brackets\n",
    "new_value_labels_list = [new_value_labels1, new_value_labels2, new_value_labels3]\n",
    "\n",
    "# Iterar sobre las listas y actualizar los diccionarios\n",
    "for i in range(1, 4): #initiates a loop that iterates over the range of values 1 to 4\n",
    "    var_labels.update(globals()[f\"new_var_labels{i}\"]) #In each iteration of the loop, it dynamically constructs a variable using an f-string\n",
    "    value_labels.update(globals()[f\"new_value_labels{i}\"]) #The same is done for value labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7816789-796a-46f9-99de-fb42b8f27974",
   "metadata": {},
   "source": [
    "Then, the results are saved to the file endes_2019 file using the function update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5284c8e-0e1c-453a-bcc1-a9354fc8a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizar endes_2019 con los diccionarios unificados\n",
    "endes_2019.update({'var_labels': var_labels, 'value_labels': value_labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11ef2c-96c0-497f-a892-958f84ff1f3b",
   "metadata": {},
   "source": [
    "## 6. Replication of the previous code\n",
    "Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7c01e-fca8-44a7-bae8-867b969eada2",
   "metadata": {},
   "source": [
    "### _Solution_\n",
    "We created a loop that automatizes the previous process. For that, we followed some steps:\n",
    "1. Creation of a list, composed of the years (corresponding to both the folder and future dataset names) of interest.\n",
    "2. Creation of an empty dictionnary to store all the data to be created in the loop\n",
    "\n",
    "3. Activation of the **for** loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2cd08-b69c-4327-bdd8-f8860bb0face",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a list, composed of the years (corresponding to both the folder and future dataset names) of interest.\n",
    "years = [2019, 2018, 2017, 2016, 2015]\n",
    "\n",
    "# Creation of an empty dictionnary to store all the data to be created in the loop\n",
    "all_data = {}\n",
    "\n",
    "# Iterate over each year\n",
    "for year in years: #Creates a loop that iterates for each item of the years list the following tasks:\n",
    "    \n",
    "    # Construct the path to the data files for the current year\n",
    "    data_path = \"D:\\\\Users\\\\yanell.huaman\\\\OneDrive\\\\Documentos\\\\GitHub\\\\Diplomado_PUCP\\\\_data\\\\endes\\\\2019\"\n",
    "        #data_path = \"D:\\\\tarea 3\\\\_data\\\\endes\\\\2019\"\n",
    "    \n",
    "    # Import data for each REC file:\n",
    "        # Reads the SPSS files for three REC datasets for the current year and retrieves metadata using pyreadstat\n",
    "        # rec_{i} contains the data, meta_{i} the metadata. This works because pyreadstat returns a tuple object that contains both types of files.\n",
    "            #That process is called tuple unpacking\n",
    "    rec_1, meta_1 = pyreadstat.read_sav(os.path.join(data_path, 'REC0111.sav')) \n",
    "    rec_2, meta_2 = pyreadstat.read_sav(os.path.join(data_path, 'RE223132.sav'))\n",
    "    rec_3, meta_3 = pyreadstat.read_sav(os.path.join(data_path, 'RE516171.sav'))\n",
    "    \n",
    "    # Select columns for each data set\n",
    "        #First, a list composed of the columns of interest is created\n",
    "    cols1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "        #Then the list is used as an argument for the creation of a subset by using the function loc. It selects all rows, and variables included in the previous list.\n",
    "    rec1_1 = rec_1.loc[:, cols1]\n",
    "    \n",
    "        #The same is done for the other datasets:\n",
    "    cols2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "    rec2_1 = rec_2.loc[:, cols2]\n",
    "\n",
    "    cols3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "    rec3_1 = rec_3.loc[:, cols3]\n",
    "    \n",
    "    # Generate a new column for rec1_1, named year\n",
    "    rec1_1.loc[:, 'year'] = year\n",
    "    \n",
    "    # Update var_labels dictionary\n",
    "    var_labels = {} #Repetition of process from task 5\n",
    "    var_labels.update(meta_1.column_names_to_labels)\n",
    "    var_labels.update(meta_2.column_names_to_labels)\n",
    "    var_labels.update(meta_3.column_names_to_labels)\n",
    "    \n",
    "    # Update value_labels dictionary\n",
    "    value_labels = {} #Repetition of process from task 5\n",
    "    value_labels.update(meta_1.variable_value_labels)\n",
    "    value_labels.update(meta_2.variable_value_labels)\n",
    "    value_labels.update(meta_3.variable_value_labels)\n",
    "    \n",
    "    # Merge data sets\n",
    "        #Merges al 3 datasets created so far in the loop, by CASEID and as an outer merge.\n",
    "    endes_data = rec1_1.merge(rec2_1, on='CASEID', how='outer')\n",
    "    endes_data = endes_data.merge(rec3_1, on='CASEID', how='outer')\n",
    "    \n",
    "    # Store data, var_labels, and value_labels in the nested dictionary \n",
    "    all_data[f'year_{year}'] = {'data': endes_data, 'var_labels': var_labels, 'value_labels': value_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616156b-aa4a-4749-a597-140f3d00c11c",
   "metadata": {},
   "source": [
    "After that, we verify the structure of the data created to check if it has been imported properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e82fd0-9968-43e1-b6ef-458b4ccaa64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all_data\n",
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
