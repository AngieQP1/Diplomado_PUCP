{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install pyreadstat\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "\n",
    "rec_1 = pd.read_spss(r\"../../_data/endes/2019/REC0111.sav\")\n",
    "rec_2 = pd.read_spss(r\"../../_data/endes/2019/RE223132.sav\")\n",
    "rec_3 = pd.read_spss(r\"../../_data/endes/2019/RE516171.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "\n",
    "file_paths = [\n",
    "    \"../../_data/endes/2019/REC0111.sav\",\n",
    "    \"../../_data/endes/2019/RE223132.sav\",\n",
    "    \"../../_data/endes/2019/RE516171.sav\"\n",
    "]\n",
    "\n",
    "var_labels = {}\n",
    "value_labels = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df, meta = pyreadstat.read_sav(file_path, apply_value_formats=True)\n",
    "\n",
    "    # Extract variable labels\n",
    "    if isinstance(meta.column_labels, list):\n",
    "        var_labels[file_path] = {col: label for col, label in zip(df.columns, meta.column_labels)}\n",
    "    else:\n",
    "        var_labels[file_path] = meta.column_labels\n",
    "\n",
    "    # Extract value labels\n",
    "    value_labels[file_path] = meta.variable_value_labels\n",
    "\n",
    "# Access variable and value labels for each file\n",
    "var_labels1 = var_labels[\"../../_data/endes/2019/REC0111.sav\"]\n",
    "var_labels2 = var_labels[\"../../_data/endes/2019/RE223132.sav\"]\n",
    "var_labels3 = var_labels[\"../../_data/endes/2019/RE516171.sav\"]\n",
    "\n",
    "value_labels1 = value_labels[\"../../_data/endes/2019/REC0111.sav\"]\n",
    "value_labels2 = value_labels[\"../../_data/endes/2019/RE223132.sav\"]\n",
    "value_labels3 = value_labels[\"../../_data/endes/2019/RE516171.sav\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the selected columns for each rec\n",
    "selected_columns_rec = [\n",
    "    ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133'],\n",
    "    ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380'],\n",
    "    ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "]\n",
    "\n",
    "# Iterate through the selected columns and perform the operations\n",
    "rec_list = [rec_1, rec_2, rec_3]\n",
    "new_var_labels_list = [var_labels1, var_labels2, var_labels3]\n",
    "new_value_labels_list = [value_labels1, value_labels2, value_labels3]\n",
    "\n",
    "for i in range(3):\n",
    "    # Update rec_i with selected columns\n",
    "    rec_i = rec_list[i].loc[:, selected_columns_rec[i]]\n",
    "\n",
    "    # Update variable labels for rec_i\n",
    "    new_var_labels_i = {key: value for key, value in new_var_labels_list[i].items() if key in selected_columns_rec[i]}\n",
    "\n",
    "    # Update value labels for rec_i\n",
    "    new_value_labels_i = {key: value for key, value in new_value_labels_list[i].items() if key in selected_columns_rec[i]}\n",
    "    \n",
    "    if i == 0:\n",
    "        rec1_1 = rec_i\n",
    "        new_var_labels1 = new_var_labels_i\n",
    "        new_value_labels1 = new_value_labels_i\n",
    "    elif i == 1:\n",
    "        rec2_1 = rec_i\n",
    "        new_var_labels2 = new_var_labels_i\n",
    "        new_value_labels2 = new_value_labels_i\n",
    "    elif i == 2:\n",
    "        rec3_1 = rec_i\n",
    "        new_var_labels3 = new_var_labels_i\n",
    "        new_value_labels3 = new_value_labels_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new column 'year' with the value 2019 using loc\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# Update var_labels1 dictionary using the update method\n",
    "new_var_labels1.update({'year': 'Year of the survey'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge rec1_1, rec2_1, and rec3_1 using CASEID\n",
    "endes_2019 = rec1_1.merge(rec2_1, on='CASEID').merge(rec3_1, on='CASEID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify new_var_labels and new_value_labels into var_labels and value_labels\n",
    "var_labels = {}\n",
    "value_labels = {}\n",
    "\n",
    "# Update var_labels and value_labels with the dictionaries from each rec dataframe\n",
    "var_labels.update(new_var_labels1)\n",
    "var_labels.update(new_var_labels2)\n",
    "var_labels.update(new_var_labels3)\n",
    "\n",
    "value_labels.update(new_value_labels1)\n",
    "value_labels.update(new_value_labels2)\n",
    "value_labels.update(new_value_labels3)\n",
    "\n",
    "# Generate new attributes for endes_2019\n",
    "endes_2019['var_labels'] = var_labels\n",
    "endes_2019['value_labels'] = value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Initialize the nested dictionary\n",
    "all_data = {}\n",
    "\n",
    "# Specify the years\n",
    "years = [2019, 2018, 2017, 2016, 2015]\n",
    "\n",
    "# Specify the filenames\n",
    "filenames = [\"REC0111.sav\", \"RE223132.sav\", \"RE516171.sav\"]\n",
    "\n",
    "# Define the selected columns for each rec\n",
    "selected_columns_rec = [\n",
    "    ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133'],\n",
    "    ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380'],\n",
    "    ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "]\n",
    "\n",
    "# Iterate through each year\n",
    "for year in years:\n",
    "    # Initialize a dictionary for the current year\n",
    "    year_data = {}\n",
    "\n",
    "    # Loop through each filename for the current year\n",
    "    for filename in filenames:\n",
    "        # Construct the file path\n",
    "        file_path = f\"../../_data/endes/{year}/{filename}\"\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(file_path):\n",
    "            # Load data from the .sav file\n",
    "            data = pd.read_spss(file_path)\n",
    "\n",
    "            # Check for the existence of selected columns\n",
    "            selected_columns = [col for col in selected_columns_rec[filenames.index(filename)] if col in data.columns]\n",
    "\n",
    "            # Select the desired columns\n",
    "            rec_i = data.loc[:, selected_columns]\n",
    "\n",
    "            # Add a new column 'year' with the value of the current year\n",
    "            rec_i['year'] = year\n",
    "\n",
    "            # Update variable labels for rec_i\n",
    "            new_var_labels_i = {key: value for key, value in new_var_labels_list[filenames.index(filename)].items() if key in selected_columns}\n",
    "\n",
    "            # Update value labels for rec_i\n",
    "            new_value_labels_i = {key: value for key, value in new_value_labels_list[filenames.index(filename)].items() if key in selected_columns}\n",
    "\n",
    "            # Store data, var_labels, and value_labels in a nested dictionary\n",
    "            file_key = f\"{os.path.splitext(filename)[0]}_{year}\"\n",
    "            year_data[file_key] = {\n",
    "                'data': rec_i,\n",
    "                'var_labels': new_var_labels_i,\n",
    "                'value_labels': new_value_labels_i\n",
    "            }\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "\n",
    "    # Store the data for the current year in the main dictionary\n",
    "    year_key = f\"year_{year}\"\n",
    "    all_data[year_key] = year_data\n",
    "\n",
    "    # Merge rec_i dataframes using CASEID for the current year\n",
    "    merged_data = None\n",
    "    for file_key in year_data.keys():\n",
    "        if merged_data is None:\n",
    "            merged_data = year_data[file_key]['data']\n",
    "        else:\n",
    "            merged_data = merged_data.merge(year_data[file_key]['data'], on='CASEID')\n",
    "\n",
    "    # Unify new_var_labels and new_value_labels into var_labels and value_labels for the current year\n",
    "    var_labels = {}\n",
    "    value_labels = {}\n",
    "\n",
    "    for file_key in year_data.keys():\n",
    "        var_labels.update(year_data[file_key]['var_labels'])\n",
    "        value_labels.update(year_data[file_key]['value_labels'])\n",
    "\n",
    "    # Generate new attributes for the merged data for the current year\n",
    "    merged_data['var_labels'] = var_labels\n",
    "    merged_data['value_labels'] = value_labels\n",
    "\n",
    "    # Add the merged data for the current year to the main dictionary\n",
    "    all_data[year_key]['merged_data'] = merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
