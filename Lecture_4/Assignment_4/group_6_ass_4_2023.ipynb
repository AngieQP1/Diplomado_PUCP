{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install pyreadstat\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "\n",
    "rec_1 = pd.read_spss(r\"../../_data/endes/2019/REC0111.sav\")\n",
    "rec_2 = pd.read_spss(r\"../../_data/endes/2019/RE223132.sav\")\n",
    "rec_3 = pd.read_spss(r\"../../_data/endes/2019/RE516171.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "\n",
    "file_paths = [\n",
    "    \"../../_data/endes/2019/REC0111.sav\",\n",
    "    \"../../_data/endes/2019/RE223132.sav\",\n",
    "    \"../../_data/endes/2019/RE516171.sav\"\n",
    "]\n",
    "\n",
    "var_labels = {}\n",
    "value_labels = {}\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df, meta = pyreadstat.read_sav(file_path, apply_value_formats=True)\n",
    "\n",
    "    # Extract variable labels\n",
    "    if isinstance(meta.column_labels, list):\n",
    "        var_labels[file_path] = {col: label for col, label in zip(df.columns, meta.column_labels)}\n",
    "    else:\n",
    "        var_labels[file_path] = meta.column_labels\n",
    "\n",
    "    # Extract value labels\n",
    "    value_labels[file_path] = meta.variable_value_labels\n",
    "\n",
    "# Access variable and value labels for each file\n",
    "var_labels1 = var_labels[\"../../_data/endes/2019/REC0111.sav\"]\n",
    "var_labels2 = var_labels[\"../../_data/endes/2019/RE223132.sav\"]\n",
    "var_labels3 = var_labels[\"../../_data/endes/2019/RE516171.sav\"]\n",
    "\n",
    "value_labels1 = value_labels[\"../../_data/endes/2019/REC0111.sav\"]\n",
    "value_labels2 = value_labels[\"../../_data/endes/2019/RE223132.sav\"]\n",
    "value_labels3 = value_labels[\"../../_data/endes/2019/RE516171.sav\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the selected columns for each rec\n",
    "selected_columns_rec = [\n",
    "    ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133'],\n",
    "    ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380'],\n",
    "    ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "]\n",
    "\n",
    "# Iterate through the selected columns and perform the operations\n",
    "rec_list = [rec_1, rec_2, rec_3]\n",
    "new_var_labels_list = [var_labels1, var_labels2, var_labels3]\n",
    "new_value_labels_list = [value_labels1, value_labels2, value_labels3]\n",
    "\n",
    "for i in range(3):\n",
    "    # Update rec_i with selected columns\n",
    "    rec_i = rec_list[i].loc[:, selected_columns_rec[i]]\n",
    "\n",
    "    # Update variable labels for rec_i\n",
    "    new_var_labels_i = {key: value for key, value in new_var_labels_list[i].items() if key in selected_columns_rec[i]}\n",
    "\n",
    "    # Update value labels for rec_i\n",
    "    new_value_labels_i = {key: value for key, value in new_value_labels_list[i].items() if key in selected_columns_rec[i]}\n",
    "    \n",
    "    if i == 0:\n",
    "        rec1_1 = rec_i\n",
    "        new_var_labels1 = new_var_labels_i\n",
    "        new_value_labels1 = new_value_labels_i\n",
    "    elif i == 1:\n",
    "        rec2_1 = rec_i\n",
    "        new_var_labels2 = new_var_labels_i\n",
    "        new_value_labels2 = new_value_labels_i\n",
    "    elif i == 2:\n",
    "        rec3_1 = rec_i\n",
    "        new_var_labels3 = new_var_labels_i\n",
    "        new_value_labels3 = new_value_labels_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new column 'year' with the value 2019 using loc\n",
    "rec1_1.loc[:, 'year'] = 2019\n",
    "\n",
    "# Update var_labels1 dictionary using the update method\n",
    "new_var_labels1.update({'year': 'Year of the survey'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge rec1_1, rec2_1, and rec3_1 using CASEID\n",
    "endes_2019 = rec1_1.merge(rec2_1, on='CASEID').merge(rec3_1, on='CASEID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify new_var_labels and new_value_labels into var_labels and value_labels\n",
    "var_labels = {}\n",
    "value_labels = {}\n",
    "\n",
    "# Update var_labels and value_labels with the dictionaries from each rec dataframe\n",
    "var_labels.update(new_var_labels1)\n",
    "var_labels.update(new_var_labels2)\n",
    "var_labels.update(new_var_labels3)\n",
    "\n",
    "value_labels.update(new_value_labels1)\n",
    "value_labels.update(new_value_labels2)\n",
    "value_labels.update(new_value_labels3)\n",
    "\n",
    "# Generate new attributes for endes_2019\n",
    "endes_2019['var_labels'] = var_labels\n",
    "endes_2019['value_labels'] = value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Initialize the nested dictionary\n",
    "all_data = {}\n",
    "\n",
    "# Specify the years\n",
    "years = [2019, 2018, 2017, 2016, 2015]\n",
    "\n",
    "# Specify the filenames\n",
    "filenames = [\"REC0111.sav\", \"RE223132.sav\", \"RE516171.sav\"]\n",
    "\n",
    "# Define the selected columns for each rec\n",
    "selected_columns_rec = [\n",
    "    ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133'],\n",
    "    ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380'],\n",
    "    ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "]\n",
    "\n",
    "# Iterate through each year\n",
    "for year in years:\n",
    "    # Initialize a dictionary for the current year\n",
    "    year_data = {}\n",
    "\n",
    "    # Loop through each filename for the current year\n",
    "    for filename in filenames:\n",
    "        # Construct the file path\n",
    "        file_path = f\"../../_data/endes/{year}/{filename}\"\n",
    "\n",
    "        # Check if the file exists\n",
    "        if os.path.exists(file_path):\n",
    "            # Load data from the .sav file\n",
    "            data = pd.read_spss(file_path)\n",
    "\n",
    "            # Check for the existence of selected columns\n",
    "            selected_columns = [col for col in selected_columns_rec[filenames.index(filename)] if col in data.columns]\n",
    "\n",
    "            # Select the desired columns\n",
    "            rec_i = data.loc[:, selected_columns]\n",
    "\n",
    "            # Add a new column 'year' with the value of the current year\n",
    "            rec_i['year'] = year\n",
    "\n",
    "            # Update variable labels for rec_i\n",
    "            new_var_labels_i = {key: value for key, value in new_var_labels_list[filenames.index(filename)].items() if key in selected_columns}\n",
    "\n",
    "            # Update value labels for rec_i\n",
    "            new_value_labels_i = {key: value for key, value in new_value_labels_list[filenames.index(filename)].items() if key in selected_columns}\n",
    "\n",
    "            # Store data, var_labels, and value_labels in a nested dictionary\n",
    "            file_key = f\"{os.path.splitext(filename)[0]}_{year}\"\n",
    "            year_data[file_key] = {\n",
    "                'data': rec_i,\n",
    "                'var_labels': new_var_labels_i,\n",
    "                'value_labels': new_value_labels_i\n",
    "            }\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "\n",
    "    # Store the data for the current year in the main dictionary\n",
    "    year_key = f\"year_{year}\"\n",
    "    all_data[year_key] = year_data\n",
    "\n",
    "    # Merge rec_i dataframes using CASEID for the current year\n",
    "    merged_data = None\n",
    "    for file_key in year_data.keys():\n",
    "        if merged_data is None:\n",
    "            merged_data = year_data[file_key]['data']\n",
    "        else:\n",
    "            merged_data = merged_data.merge(year_data[file_key]['data'], on='CASEID')\n",
    "\n",
    "    # Unify new_var_labels and new_value_labels into var_labels and value_labels for the current year\n",
    "    var_labels = {}\n",
    "    value_labels = {}\n",
    "\n",
    "    for file_key in year_data.keys():\n",
    "        var_labels.update(year_data[file_key]['var_labels'])\n",
    "        value_labels.update(year_data[file_key]['value_labels'])\n",
    "\n",
    "    # Generate new attributes for the merged data for the current year\n",
    "    merged_data['var_labels'] = var_labels\n",
    "    merged_data['value_labels'] = value_labels\n",
    "\n",
    "    # Add the merged data for the current year to the main dictionary\n",
    "    all_data[year_key]['merged_data'] = merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/g41z_k153vvbyk6y_3whxsjc0000gn/T/ipykernel_29180/1359047690.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  endes_data_2015_2019 = pd.concat(all_datasets, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a list to store all data sets\n",
    "all_datasets = []\n",
    "\n",
    "# Iterate through each year in all_data\n",
    "for year_key in all_data.keys():\n",
    "    # Get the merged_data for the current year\n",
    "    merged_data = all_data[year_key].get('merged_data')\n",
    "\n",
    "    # Check if merged_data is not None\n",
    "    if merged_data is not None:\n",
    "        # Append the current merged_data to the list\n",
    "        all_datasets.append(merged_data)\n",
    "\n",
    "# Concatenate all data sets into a single DataFrame\n",
    "endes_data_2015_2019 = pd.concat(all_datasets, ignore_index=True)\n",
    "\n",
    "# Reset the index for a clean DataFrame\n",
    "endes_data_2015_2019.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V000</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V007</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>V010</th>\n",
       "      <th>...</th>\n",
       "      <th>V511</th>\n",
       "      <th>V512</th>\n",
       "      <th>V513</th>\n",
       "      <th>V525</th>\n",
       "      <th>V613</th>\n",
       "      <th>V714</th>\n",
       "      <th>V715</th>\n",
       "      <th>year</th>\n",
       "      <th>var_labels</th>\n",
       "      <th>value_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>De 10 a 14 años</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sí</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000102801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>De 5 a 9 años</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sí</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000102801  6</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>De 30 a más años</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000104801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>De 5 a 9 años</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000113601  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>De 10 a 14 años</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sí</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170371</th>\n",
       "      <td>317503501  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5-9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170372</th>\n",
       "      <td>317503701  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20-24</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170373</th>\n",
       "      <td>317507601  1</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20-24</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170374</th>\n",
       "      <td>317507801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not had intercourse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170375</th>\n",
       "      <td>317508001  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10-14</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170376 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    CASEID V000    V001   V002  V003    V004    V007    V008  \\\n",
       "0             000100201  2  PE6     1.0    2.0   2.0     1.0  2019.0  1434.0   \n",
       "1             000102801  2  PE6     1.0   28.0   2.0     1.0  2019.0  1434.0   \n",
       "2             000102801  6  PE6     1.0   28.0   6.0     1.0  2019.0  1434.0   \n",
       "3             000104801  2  PE6     1.0   48.0   2.0     1.0  2019.0  1434.0   \n",
       "4             000113601  2  PE6     1.0  136.0   2.0     1.0  2019.0  1434.0   \n",
       "...                    ...  ...     ...    ...   ...     ...     ...     ...   \n",
       "170371        317503501  2  PE6  3175.0   35.0   2.0  3175.0  2015.0  1389.0   \n",
       "170372        317503701  2  PE6  3175.0   37.0   2.0  3175.0  2015.0  1389.0   \n",
       "170373        317507601  1  PE6  3175.0   76.0   1.0  3175.0  2015.0  1389.0   \n",
       "170374        317507801  2  PE6  3175.0   78.0   2.0  3175.0  2015.0  1389.0   \n",
       "170375        317508001  2  PE6  3175.0   80.0   2.0  3175.0  2015.0  1389.0   \n",
       "\n",
       "        V009    V010  ...  V511  V512              V513                 V525  \\\n",
       "0        4.0  1986.0  ...  21.0  11.0   De 10 a 14 años                 17.0   \n",
       "1        6.0  1983.0  ...  28.0   7.0     De 5 a 9 años                 18.0   \n",
       "2        3.0  1970.0  ...  14.0  34.0  De 30 a más años                 14.0   \n",
       "3        5.0  1991.0  ...  18.0   9.0     De 5 a 9 años                 15.0   \n",
       "4       11.0  1988.0  ...  17.0  13.0   De 10 a 14 años                 15.0   \n",
       "...      ...     ...  ...   ...   ...               ...                  ...   \n",
       "170371   1.0  1989.0  ...  19.0   7.0               5-9                 15.0   \n",
       "170372  12.0  1970.0  ...  20.0  24.0             20-24                 14.0   \n",
       "170373  10.0  1972.0  ...  20.0  22.0             20-24                 12.0   \n",
       "170374   4.0  2000.0  ...   NaN   NaN     Never married  Not had intercourse   \n",
       "170375   7.0  1984.0  ...  19.0  11.0             10-14                 18.0   \n",
       "\n",
       "       V613 V714  V715  year var_labels value_labels  \n",
       "0       2.0   Sí  11.0  2019        NaN          NaN  \n",
       "1       3.0   Sí  14.0  2019        NaN          NaN  \n",
       "2       0.0   No   6.0  2019        NaN          NaN  \n",
       "3       2.0   No   6.0  2019        NaN          NaN  \n",
       "4       2.0   Sí  16.0  2019        NaN          NaN  \n",
       "...     ...  ...   ...   ...        ...          ...  \n",
       "170371  1.0  Yes  11.0  2015        NaN          NaN  \n",
       "170372  3.0  Yes   0.0  2015        NaN          NaN  \n",
       "170373  3.0  Yes   3.0  2015        NaN          NaN  \n",
       "170374  2.0   No   NaN  2015        NaN          NaN  \n",
       "170375  2.0   No  11.0  2015        NaN          NaN  \n",
       "\n",
       "[170376 rows x 68 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endes_data_2015_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'var_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#Second, we use a for loop to iterate over the years from 2015 to 2019.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#We are extracting the variable and value labels associated with each year from all_data. Then we store them in the all_value_labels dictionary with the year as the key.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m( \u001b[38;5;241m2015\u001b[39m, \u001b[38;5;241m2020\u001b[39m ):\n\u001b[0;32m---> 10\u001b[0m     all_var_labels[year] \u001b[38;5;241m=\u001b[39m all_data[ \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m ][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     all_value_labels[year] \u001b[38;5;241m=\u001b[39m all_data[ \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m ][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m all_var_labels\n",
      "\u001b[0;31mKeyError\u001b[0m: 'var_labels'"
     ]
    }
   ],
   "source": [
    "#First, we create 2 new dictionaries.\n",
    "all_var_labels = {}\n",
    "all_value_labels = {}\n",
    "\n",
    "#Second, we use a for loop to iterate over the years from 2015 to 2019.\n",
    "\n",
    "#We are extracting the variable and value labels associated with each year from all_data. Then we store them in the all_value_labels dictionary with the year as the key.\n",
    "\n",
    "for year in range( 2015, 2020 ):\n",
    "    all_var_labels[year] = all_data[ f'year_{year}' ]['var_labels']\n",
    "    all_value_labels[year] = all_data[ f'year_{year}' ]['value_labels']\n",
    "\n",
    "all_var_labels\n",
    "all_value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V000</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V007</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>V010</th>\n",
       "      <th>...</th>\n",
       "      <th>V511</th>\n",
       "      <th>V512</th>\n",
       "      <th>V513</th>\n",
       "      <th>V525</th>\n",
       "      <th>V613</th>\n",
       "      <th>V714</th>\n",
       "      <th>V715</th>\n",
       "      <th>year</th>\n",
       "      <th>var_labels</th>\n",
       "      <th>value_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000102701  1</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10-14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000104301  1</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5-9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000104801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15-19</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000104801  3</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not had intercourse</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000105001  3</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never married</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35761</th>\n",
       "      <td>317503501  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5-9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35762</th>\n",
       "      <td>317503701  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20-24</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35763</th>\n",
       "      <td>317507601  1</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20-24</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35764</th>\n",
       "      <td>317507801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never married</td>\n",
       "      <td>Not had intercourse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35765</th>\n",
       "      <td>317508001  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10-14</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35766 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CASEID V000    V001  V002  V003    V004    V007    V008  \\\n",
       "0            000102701  1  PE6     1.0  27.0   1.0     1.0  2015.0  1386.0   \n",
       "1            000104301  1  PE6     1.0  43.0   1.0     1.0  2015.0  1386.0   \n",
       "2            000104801  2  PE6     1.0  48.0   2.0     1.0  2015.0  1386.0   \n",
       "3            000104801  3  PE6     1.0  48.0   3.0     1.0  2015.0  1386.0   \n",
       "4            000105001  3  PE6     1.0  50.0   3.0     1.0  2015.0  1386.0   \n",
       "...                   ...  ...     ...   ...   ...     ...     ...     ...   \n",
       "35761        317503501  2  PE6  3175.0  35.0   2.0  3175.0  2015.0  1389.0   \n",
       "35762        317503701  2  PE6  3175.0  37.0   2.0  3175.0  2015.0  1389.0   \n",
       "35763        317507601  1  PE6  3175.0  76.0   1.0  3175.0  2015.0  1389.0   \n",
       "35764        317507801  2  PE6  3175.0  78.0   2.0  3175.0  2015.0  1389.0   \n",
       "35765        317508001  2  PE6  3175.0  80.0   2.0  3175.0  2015.0  1389.0   \n",
       "\n",
       "       V009    V010  ...  V511  V512           V513                 V525 V613  \\\n",
       "0       7.0  1985.0  ...  16.0  13.0          10-14                 15.0  4.0   \n",
       "1       4.0  1974.0  ...  33.0   8.0            5-9                 26.0  2.0   \n",
       "2       1.0  1980.0  ...  18.0  17.0          15-19                 18.0  1.0   \n",
       "3      11.0  1999.0  ...   NaN   NaN  Never married  Not had intercourse  0.0   \n",
       "4       8.0  1993.0  ...   NaN   NaN  Never married                 21.0  2.0   \n",
       "...     ...     ...  ...   ...   ...            ...                  ...  ...   \n",
       "35761   1.0  1989.0  ...  19.0   7.0            5-9                 15.0  1.0   \n",
       "35762  12.0  1970.0  ...  20.0  24.0          20-24                 14.0  3.0   \n",
       "35763  10.0  1972.0  ...  20.0  22.0          20-24                 12.0  3.0   \n",
       "35764   4.0  2000.0  ...   NaN   NaN  Never married  Not had intercourse  2.0   \n",
       "35765   7.0  1984.0  ...  19.0  11.0          10-14                 18.0  2.0   \n",
       "\n",
       "      V714  V715  year var_labels value_labels  \n",
       "0      Yes   3.0  2015        NaN          NaN  \n",
       "1       No   9.0  2015        NaN          NaN  \n",
       "2      Yes  11.0  2015        NaN          NaN  \n",
       "3      Yes   NaN  2015        NaN          NaN  \n",
       "4       No   NaN  2015        NaN          NaN  \n",
       "...    ...   ...   ...        ...          ...  \n",
       "35761  Yes  11.0  2015        NaN          NaN  \n",
       "35762  Yes   0.0  2015        NaN          NaN  \n",
       "35763  Yes   3.0  2015        NaN          NaN  \n",
       "35764   No   NaN  2015        NaN          NaN  \n",
       "35765   No  11.0  2015        NaN          NaN  \n",
       "\n",
       "[35766 rows x 68 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, we set the attributes var_label and value_labels which are assigned the information of the dictionaries previously created.\n",
    "\n",
    "endes_data_2015_2019_ta.attrs[ 'var_labels' ] = all_var_labels\n",
    "endes_data_2015_2019_ta.attrs[ 'value_labels' ] = all_value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
